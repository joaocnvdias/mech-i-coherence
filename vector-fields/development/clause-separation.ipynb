{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0abc663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdias/miniconda3/envs/vf/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import spacy\n",
    "import re \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4bab150",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"roneneldan/TinyStories\")\n",
    "tiny_train = ds['train']\n",
    "tiny_val = ds['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0d12afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One day, a little fish named Fin was swimming near the shore. He saw a big crab and wanted to be friends. \"Hi, I am Fin. Do you want to play?\" asked the little fish. The crab looked at Fin and said, \"No, I don\\'t want to play. I am cold and I don\\'t feel fine.\"\\n\\nFin felt sad but wanted to help the crab feel better. He swam away and thought of a plan. He remembered that the sun could make things warm. So, Fin swam to the top of the water and called to the sun, \"Please, sun, help my new friend feel fine and not freeze!\"\\n\\nThe sun heard Fin\\'s call and shone its warm light on the shore. The crab started to feel better and not so cold. He saw Fin and said, \"Thank you, little fish, for making me feel fine. I don\\'t feel like I will freeze now. Let\\'s play together!\" And so, Fin and the crab played and became good friends.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_train['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6747e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = tiny_train[\"text\"][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6651701",
   "metadata": {},
   "source": [
    "## Spacy Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531b37cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM\n",
      "NOUN\n",
      "PUNCT\n",
      "DET\n",
      "ADJ\n",
      "NOUN\n",
      "VERB\n",
      "PROPN\n",
      "VERB\n",
      "DET\n",
      "NOUN\n",
      "ADP\n",
      "PRON\n",
      "NOUN\n",
      "PUNCT\n"
     ]
    }
   ],
   "source": [
    "nlp_model = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "test = nlp_model(subjects[0])\n",
    "\n",
    "for sentence in test.sents:\n",
    "    for token in sentence:\n",
    "        print(token.pos_)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4804d7",
   "metadata": {},
   "source": [
    "## Clause separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0cecaac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClauseSeparator:\n",
    "    def __init__(self, size = 'small'):\n",
    "        if size == 'small':\n",
    "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        elif size == 'large':\n",
    "            self.nlp = spacy.load(\"en_core_web_trf\")\n",
    "        else:\n",
    "            print(\"Choose an appropriate spaCy model. Ex install: python -m spacy download en_core_web_sm\")\n",
    "            self.nlp = None\n",
    "    \n",
    "    def clause_split(self, text):\n",
    "        \"\"\"\n",
    "        Find clause boundaries based on conjunctions and punctuation.    \n",
    "        Note we don't need to add periods to the rules because we iterate through\n",
    "        the sentences in the documents. \n",
    "        \"\"\"\n",
    "        if not self.nlp:\n",
    "            return None\n",
    "        \n",
    "        doc = self.nlp(text)\n",
    "        clauses = []\n",
    "        \n",
    "        for sentence in doc.sents:\n",
    "            \n",
    "            sent_clauses = []\n",
    "            current_tokens = []\n",
    "            \n",
    "            for token in sentence:\n",
    "                current_tokens.append(token.text)\n",
    "\n",
    "                #check for what decides a new clause\n",
    "                if (token.dep_ in ['cc', 'mark'] or  #coordinating/subordinating conjunctions\n",
    "                    token.text in [',', ';', ':'] or\n",
    "                    token.pos_ == 'SCONJ'):  #subordinating conjunction\n",
    "                    \n",
    "                    if len(current_tokens) > 1:  #dont create single-word clauses\n",
    "                        clause_text = ' '.join(current_tokens[:-1]).strip() #everything before curent token - that will go to the next clause\n",
    "                        if clause_text:\n",
    "                            sent_clauses.append(clause_text)\n",
    "                        current_tokens = [token.text] if token.text not in [',', ';', ':'] else [] #boundary token if not punctuation\n",
    "\n",
    "            #sentence over, add remaining tokens of sentence as final clause\n",
    "            if current_tokens:\n",
    "                clause_text = ' '.join(current_tokens).strip()\n",
    "                if clause_text:\n",
    "                    sent_clauses.append(clause_text)\n",
    "    \n",
    "            #safeguard\n",
    "            if not sent_clauses:\n",
    "                sent_clauses.append(sentence.text.strip())\n",
    "                \n",
    "            clauses.extend(sent_clauses)\n",
    "        \n",
    "        return clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82715380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. One day\n",
      "2. a little girl named Lily found a needle in her room .\n",
      "3. She knew it was difficult to play with it\n",
      "4. because it was sharp .\n",
      "5. Lily wanted to share the needle with her mom\n",
      "6. so she could sew a button on her shirt .\n",
      "7. Lily went to her mom\n",
      "8. and said\n",
      "9. \" Mom\n",
      "10. I found this needle .\n",
      "11. Can you share it with me\n",
      "12. and sew my shirt ? \"\n",
      "13. Her mom smiled\n",
      "14. and said\n",
      "15. \" Yes\n",
      "16. Lily\n",
      "17. we can share the needle\n",
      "18. and fix your shirt .\n",
      "19. \" \n",
      "\n",
      " Together\n",
      "20. they shared the needle\n",
      "21. and sewed the button on Lily 's shirt .\n",
      "22. It was not difficult for them\n",
      "23. because they were sharing\n",
      "24. and helping each other .\n",
      "25. After they finished\n",
      "26. Lily thanked her mom for sharing the needle\n",
      "27. and fixing her shirt .\n",
      "28. They both felt happy\n",
      "29. because they had shared\n",
      "30. and worked together .\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train[:5]\")  # first 5 stories\n",
    "\n",
    "separator = ClauseSeparator()\n",
    "advanced_clauses = separator.clause_split(dataset[\"text\"][0])\n",
    "for i, clause in enumerate(advanced_clauses, 1):\n",
    "    print(f\"{i}. {clause}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8479231a",
   "metadata": {},
   "source": [
    "#### Fix for weird new line tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf788da",
   "metadata": {},
   "source": [
    "vibe-coded fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "385491af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClauseSeparator:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        except OSError:\n",
    "            print(\"spaCy model not found. Install with: python -m spacy download en_core_web_sm\")\n",
    "            self.nlp = None\n",
    "\n",
    "    def clause_split(self, text):\n",
    "        if not self.nlp:\n",
    "            return None\n",
    "\n",
    "        # Split on two-or-more newlines to preserve paragraph boundaries\n",
    "        paragraphs = re.split(r'\\n{2,}', text)\n",
    "        all_clauses = []\n",
    "\n",
    "        for para in paragraphs:\n",
    "            # collapse single newlines inside a paragraph into spaces (soft line breaks)\n",
    "            para = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', para).strip()\n",
    "            if not para:\n",
    "                continue\n",
    "\n",
    "            doc = self.nlp(para)\n",
    "            para_clauses = []\n",
    "\n",
    "            for sent in doc.sents:\n",
    "                sent_clauses = []\n",
    "                current_tokens = []\n",
    "\n",
    "                for token in sent:\n",
    "                    current_tokens.append(token.text)\n",
    "\n",
    "                    # treat punctuation and quotes as boundary chars for resetting\n",
    "                    boundary_is_punct = token.text in [',', ';', ':', '\"', '“', '”', \"'\"]\n",
    "\n",
    "                    if (token.dep_ in ['cc', 'mark'] or\n",
    "                        boundary_is_punct or\n",
    "                        token.pos_ == 'SCONJ'):\n",
    "\n",
    "                        # append clause formed by tokens up to (but not including) boundary token\n",
    "                        if len(current_tokens) > 1:\n",
    "                            clause_text = ' '.join(current_tokens[:-1]).strip()\n",
    "                            if clause_text:\n",
    "                                sent_clauses.append(clause_text)\n",
    "\n",
    "                        # reset buffer: drop punctuation, keep conjunctions/markers as start of next clause\n",
    "                        if boundary_is_punct:\n",
    "                            current_tokens = []\n",
    "                        else:\n",
    "                            current_tokens = [token.text]\n",
    "\n",
    "                # Add remaining tokens as final clause only if they have >1 token.\n",
    "                # We'll handle single-token sentence fragments in a small postprocessing step below.\n",
    "                if len(current_tokens) > 1:\n",
    "                    clause_text = ' '.join(current_tokens).strip()\n",
    "                    if clause_text:\n",
    "                        sent_clauses.append(clause_text)\n",
    "\n",
    "                # If no clause was produced for this sentence, fall back to the full sentence text\n",
    "                if not sent_clauses:\n",
    "                    sent_clauses.append(sent.text.strip())\n",
    "\n",
    "                para_clauses.extend(sent_clauses)\n",
    "\n",
    "                        # --- POST-PROCESSING: spaCy-aware merge of standalone single-token clauses forward ---\n",
    "            merged = []\n",
    "            i = 0\n",
    "            while i < len(para_clauses):\n",
    "                cur = para_clauses[i]\n",
    "                is_single_token = (len(cur.split()) == 1)\n",
    "                is_quoted = (cur.startswith('\"') or cur.startswith(\"'\") or cur.endswith('\"') or cur.endswith(\"'\"))\n",
    "\n",
    "                if is_single_token and not is_quoted and i + 1 < len(para_clauses):\n",
    "                    nxt = para_clauses[i + 1].lstrip()\n",
    "                    # safe check: next clause must exist and start with a character\n",
    "                    if nxt:\n",
    "                        first_char_next = nxt[0]\n",
    "                        # analyze the single token with spaCy to decide if it's a name/vocative/interjection\n",
    "                        try:\n",
    "                            tok = self.nlp(cur.strip())[0]\n",
    "                            pos = tok.pos_\n",
    "                            lower_form = tok.lower_\n",
    "                        except Exception:\n",
    "                            pos = None\n",
    "                            lower_form = cur.strip().lower()\n",
    "\n",
    "                        # treat explicit responses/interjections as KEEP (do not merge)\n",
    "                        interjection_whitelist = {\"yes\", \"no\", \"okay\", \"ok\", \"thanks\", \"thankyou\"}\n",
    "                        is_interjection = (pos == 'INTJ') or (lower_form in interjection_whitelist)\n",
    "\n",
    "                        # treat proper nouns (names) and titles as vocatives: KEEP (do not merge)\n",
    "                        is_proper_name = (pos == 'PROPN')\n",
    "\n",
    "                        # DECISION: merge forward only if:\n",
    "                        #  - current token is not a proper name (PROPN)\n",
    "                        #  - current token is not an interjection/response\n",
    "                        #  - and the next clause starts lowercase (indicates continuation)\n",
    "                        if (not is_proper_name) and (not is_interjection) and first_char_next.islower():\n",
    "                            merged.append(cur + ' ' + para_clauses[i + 1])\n",
    "                            i += 2\n",
    "                            continue\n",
    "\n",
    "                # default: keep current clause as-is\n",
    "                merged.append(cur)\n",
    "                i += 1\n",
    "\n",
    "            all_clauses.extend(merged)\n",
    "\n",
    "        return all_clauses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "693fa793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. One day\n",
      "2. a little girl named Lily found a needle in her room .\n",
      "3. She knew it was difficult to play with it\n",
      "4. because it was sharp .\n",
      "5. Lily wanted to share the needle with her mom\n",
      "6. so she could sew a button on her shirt .\n",
      "7. Lily went to her mom\n",
      "8. and said\n",
      "9. Mom\n",
      "10. I found this needle .\n",
      "11. Can you share it with me\n",
      "12. and sew my shirt ?\n",
      "13. Her mom smiled\n",
      "14. and said\n",
      "15. Yes\n",
      "16. Lily we can share the needle\n",
      "17. and fix your shirt .\n",
      "18. Together they shared the needle\n",
      "19. and sewed the button on Lily 's shirt .\n",
      "20. It was not difficult for them\n",
      "21. because they were sharing\n",
      "22. and helping each other .\n",
      "23. After they finished\n",
      "24. Lily thanked her mom for sharing the needle\n",
      "25. and fixing her shirt .\n",
      "26. They both felt happy\n",
      "27. because they had shared\n",
      "28. and worked together .\n"
     ]
    }
   ],
   "source": [
    "separator = ClauseSeparator()\n",
    "advanced_clauses = separator.clause_split(dataset[\"text\"][0])\n",
    "for i, clause in enumerate(advanced_clauses, 1):\n",
    "    print(f\"{i}. {clause}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee3c60a",
   "metadata": {},
   "source": [
    "## Evaluation of clause separator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca5f9c",
   "metadata": {},
   "source": [
    "#### Parsing dataset for task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80d2be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = load_dataset(\"troianea/CLAUSE-ATLAS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a211bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               book chapter_id  paragraph_id  clause_number  \\\n",
      "0  Alice's Adventures in Wonderland          1             1              0   \n",
      "1  Alice's Adventures in Wonderland          1             1              1   \n",
      "2  Alice's Adventures in Wonderland          1             1              2   \n",
      "3  Alice's Adventures in Wonderland          1             2              3   \n",
      "4  Alice's Adventures in Wonderland          1             2              4   \n",
      "\n",
      "                                                text prompt_one prompt_two  \\\n",
      "0  Alice was beginning to get very tired of sitti...          C          C   \n",
      "1  once or twice she had peeped into the book her...          S          C   \n",
      "2  “and what is the use of a book,” thought Alice...          S          S   \n",
      "3  So she was considering in her own mind (as wel...          S          S   \n",
      "4  whether the pleasure of making a daisy-chain w...          S          S   \n",
      "\n",
      "  prompt_three annotator_one annotator_two annotator_three  \\\n",
      "0            C             S             S               E   \n",
      "1            S             E             E               E   \n",
      "2            S             S             S               S   \n",
      "3            S             S             S               S   \n",
      "4            S             S             C               S   \n",
      "\n",
      "  experiencer_prompt_one experiencer_annotator_one experiencer_annotator_two  \\\n",
      "0                     --                     Alice                     Alice   \n",
      "1                  Alice                        --                        --   \n",
      "2                  Alice                     Alice                     Alice   \n",
      "3                  Alice                     Alice                     Alice   \n",
      "4                  Alice                     Alice                        --   \n",
      "\n",
      "  experiencer_annotator_three  \n",
      "0                          --  \n",
      "1                          --  \n",
      "2                       Alice  \n",
      "3                       Alice  \n",
      "4                       Alice  \n"
     ]
    }
   ],
   "source": [
    "df = eval_set[\"train\"].to_pandas()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "407fdf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[['book','paragraph_id', 'clause_number','text']]\n",
    "\n",
    "#lets use first book for now\n",
    "first_book = df_filtered['book'].iat[0]\n",
    "\n",
    "#make sure columns are int\n",
    "df_filtered_book = df_filtered[df_filtered['book'] == first_book].copy()\n",
    "df_filtered_book['paragraph_id_num'] = pd.to_numeric(df_filtered_book['paragraph_id'], errors='coerce')\n",
    "df_filtered_book['clause_number_num'] = pd.to_numeric(df_filtered_book['clause_number'], errors='coerce')\n",
    "#and sorted\n",
    "df_book = df_filtered_book.sort_values(['paragraph_id_num', 'clause_number_num'])\n",
    "\n",
    "#merge text by paragraph_id\n",
    "merged = (\n",
    "    df_book\n",
    "    .groupby('paragraph_id', sort=True, as_index=False)\n",
    "    .agg(paragraph_text=('text', lambda texts: \" \".join(t.strip() for t in texts)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d156e2e8",
   "metadata": {},
   "source": [
    "#### Creating ML dataset - X, Y structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50f2db73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>clauses</th>\n",
       "      <th>paragraph_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Alice was beginning to get very tired of sitt...</td>\n",
       "      <td>Alice was beginning to get very tired of sitti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[So she was considering in her own mind (as we...</td>\n",
       "      <td>So she was considering in her own mind (as wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[There was nothing so very remarkable in that;...</td>\n",
       "      <td>There was nothing so very remarkable in that; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[In another moment down went Alice after it,, ...</td>\n",
       "      <td>In another moment down went Alice after it, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[The rabbit-hole went straight on like a tunne...</td>\n",
       "      <td>The rabbit-hole went straight on like a tunnel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraph_id                                            clauses  \\\n",
       "0             1  [Alice was beginning to get very tired of sitt...   \n",
       "1             2  [So she was considering in her own mind (as we...   \n",
       "2             3  [There was nothing so very remarkable in that;...   \n",
       "3             4  [In another moment down went Alice after it,, ...   \n",
       "4             5  [The rabbit-hole went straight on like a tunne...   \n",
       "\n",
       "                                      paragraph_text  \n",
       "0  Alice was beginning to get very tired of sitti...  \n",
       "1  So she was considering in her own mind (as wel...  \n",
       "2  There was nothing so very remarkable in that; ...  \n",
       "3  In another moment down went Alice after it, ne...  \n",
       "4  The rabbit-hole went straight on like a tunnel...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge by paragraph id, put clauses into lists\n",
    "paragraph_clauses = (\n",
    "    df_book\n",
    "    .groupby('paragraph_id', sort=True)['text']\n",
    "    .apply(lambda texts: list(texts))\n",
    "    .reset_index(name='clauses')\n",
    ")\n",
    "\n",
    "paragraph_clauses['paragraph_text'] = paragraph_clauses['clauses'].apply(lambda cl: \" \".join(cl))\n",
    "\n",
    "paragraph_clauses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e51b44be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output:\n",
      "1: 'There seemed to be no use in waiting by the little door, so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes:'\n",
      "2: 'this time she found a little bottle on it,'\n",
      "3: '(\"which certainly was not here before,\" said Alice,)'\n",
      "4: 'and round the neck of the bottle was a paper label,'\n",
      "5: 'with the words \"DRINK ME,\" beautifully printed on it in large letters.'\n",
      "\n",
      "Gold Standard:\n",
      "1: 'There seemed to be no use in waiting by the little door,'\n",
      "2: 'so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes:'\n",
      "3: 'this time she found a little bottle on it,'\n",
      "4: '(\"which certainly was not here before,\" said Alice,)'\n",
      "5: 'and round the neck of the bottle was a paper label,'\n",
      "6: 'with the words \"DRINK ME,\" beautifully printed on it in large letters.'\n"
     ]
    }
   ],
   "source": [
    "class Claude_Advanced_ClauseSeparator:\n",
    "    def __init__(self, size='small'):\n",
    "        if size == 'small':\n",
    "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        elif size == 'large':\n",
    "            self.nlp = spacy.load(\"en_core_web_trf\")\n",
    "        else:\n",
    "            print(\"Choose an appropriate spaCy model. Ex install: python -m spacy download en_core_web_sm\")\n",
    "            self.nlp = None\n",
    "    \n",
    "    def _find_matching_bracket(self, text, start_pos, open_char):\n",
    "        \"\"\"Find matching closing bracket/quote\"\"\"\n",
    "        close_chars = {'(': ')', '\"': '\"', \"'\": \"'\", '[': ']', '{': '}'}\n",
    "        close_char = close_chars.get(open_char, open_char)\n",
    "        \n",
    "        if open_char in '\"\\'':\n",
    "            # For quotes, find the next occurrence\n",
    "            next_pos = text.find(close_char, start_pos + 1)\n",
    "            return next_pos if next_pos != -1 else len(text) - 1\n",
    "        else:\n",
    "            # For brackets, handle nesting\n",
    "            count = 1\n",
    "            for i in range(start_pos + 1, len(text)):\n",
    "                if text[i] == open_char:\n",
    "                    count += 1\n",
    "                elif text[i] == close_char:\n",
    "                    count -= 1\n",
    "                    if count == 0:\n",
    "                        return i\n",
    "            return len(text) - 1\n",
    "    \n",
    "    def clause_split(self, text):\n",
    "        \"\"\"\n",
    "        Split text into clauses using a simpler, more reliable approach.\n",
    "        \"\"\"\n",
    "        if not self.nlp:\n",
    "            return None\n",
    "        \n",
    "        doc = self.nlp(text)\n",
    "        clauses = []\n",
    "        \n",
    "        for sentence in doc.sents:\n",
    "            sentence_text = sentence.text.strip()\n",
    "            if not sentence_text:\n",
    "                continue\n",
    "            \n",
    "            # Find all potential split points\n",
    "            split_points = []\n",
    "            i = 0\n",
    "            paren_depth = 0\n",
    "            quote_depth = 0\n",
    "            quote_char = None\n",
    "            \n",
    "            # First, find parenthetical expressions to treat as separate clauses\n",
    "            parenthetical_ranges = []\n",
    "            temp_i = 0\n",
    "            while temp_i < len(sentence_text):\n",
    "                if sentence_text[temp_i] == '(':\n",
    "                    end_pos = self._find_matching_bracket(sentence_text, temp_i, '(')\n",
    "                    parenthetical_ranges.append((temp_i, end_pos))\n",
    "                    temp_i = end_pos + 1\n",
    "                else:\n",
    "                    temp_i += 1\n",
    "            \n",
    "            while i < len(sentence_text):\n",
    "                char = sentence_text[i]\n",
    "                \n",
    "                # Track parentheses and quotes\n",
    "                if char == '(' and quote_depth == 0:\n",
    "                    paren_depth += 1\n",
    "                elif char == ')' and quote_depth == 0:\n",
    "                    paren_depth -= 1\n",
    "                elif char in '\"\\'':\n",
    "                    if quote_depth == 0:\n",
    "                        quote_depth = 1\n",
    "                        quote_char = char\n",
    "                    elif char == quote_char:\n",
    "                        quote_depth = 0\n",
    "                        quote_char = None\n",
    "                \n",
    "                # Only split if we're not inside parentheses or quotes\n",
    "                if paren_depth == 0 and quote_depth == 0:\n",
    "                    # Check for clause-separating punctuation\n",
    "                    if char in ',;:':\n",
    "                        # Look at what comes after\n",
    "                        next_part = sentence_text[i+1:].strip()\n",
    "                        if next_part:\n",
    "                            # Check if this is a genuine clause boundary\n",
    "                            if char == ',' and self._is_clause_boundary_comma(sentence_text, i):\n",
    "                                split_points.append(i + 1)  # Split after comma\n",
    "                            elif char in ';:':\n",
    "                                split_points.append(i + 1)  # Split after semicolon/colon\n",
    "                \n",
    "                i += 1\n",
    "            \n",
    "            # Add parenthetical split points\n",
    "            for start, end in parenthetical_ranges:\n",
    "                if start > 0:\n",
    "                    split_points.append(start)  # Split before parenthetical\n",
    "                split_points.append(end + 1)  # Split after parenthetical\n",
    "            \n",
    "            # Also check for \"and\" and \"with\" that start new clauses\n",
    "            and_positions = []\n",
    "            words = sentence_text.split()\n",
    "            current_pos = 0\n",
    "            for word in words:\n",
    "                word_start = sentence_text.find(word, current_pos)\n",
    "                if word.lower() in ['and', 'with'] and self._should_split_on_word(sentence_text, word_start, word.lower()):\n",
    "                    # Check we're not inside parentheses\n",
    "                    temp_paren = 0\n",
    "                    temp_quote = 0\n",
    "                    temp_quote_char = None\n",
    "                    for j in range(word_start):\n",
    "                        if sentence_text[j] == '(':\n",
    "                            temp_paren += 1\n",
    "                        elif sentence_text[j] == ')':\n",
    "                            temp_paren -= 1\n",
    "                        elif sentence_text[j] in '\"\\'':\n",
    "                            if temp_quote == 0:\n",
    "                                temp_quote = 1\n",
    "                                temp_quote_char = sentence_text[j]\n",
    "                            elif sentence_text[j] == temp_quote_char:\n",
    "                                temp_quote = 0\n",
    "                    \n",
    "                    if temp_paren == 0 and temp_quote == 0:\n",
    "                        and_positions.append(word_start)\n",
    "                \n",
    "                current_pos = word_start + len(word)\n",
    "            \n",
    "            split_points.extend(and_positions)\n",
    "            split_points = sorted(set(split_points))\n",
    "            \n",
    "            # Split the sentence at the identified points\n",
    "            if not split_points:\n",
    "                clauses.append(sentence_text)\n",
    "            else:\n",
    "                start = 0\n",
    "                for split_point in split_points:\n",
    "                    clause = sentence_text[start:split_point].strip()\n",
    "                    if clause:\n",
    "                        clauses.append(clause)\n",
    "                    start = split_point\n",
    "                \n",
    "                # Add the remaining part\n",
    "                final_clause = sentence_text[start:].strip()\n",
    "                if final_clause:\n",
    "                    clauses.append(final_clause)\n",
    "        \n",
    "        return clauses\n",
    "    \n",
    "    def _is_clause_boundary_comma(self, text, comma_pos):\n",
    "        \"\"\"\n",
    "        Determine if a comma represents a clause boundary.\n",
    "        \"\"\"\n",
    "        # Get the part after the comma\n",
    "        after_comma = text[comma_pos + 1:].strip()\n",
    "        if not after_comma:\n",
    "            return False\n",
    "    \n",
    "    def _should_split_on_word(self, text, word_pos, word):\n",
    "        \"\"\"Check if we should split on words like 'and' or 'with'\"\"\"\n",
    "        after_word = text[word_pos + len(word):].strip()\n",
    "        \n",
    "        if word == 'and':\n",
    "            # Split on \"and\" if it starts a new independent clause\n",
    "            # Look for pattern: \"and [noun/pronoun] [verb]\"\n",
    "            if after_word:\n",
    "                try:\n",
    "                    doc = self.nlp(after_word)\n",
    "                    tokens = [t for t in doc if not t.is_space and t.pos_ != 'PUNCT']\n",
    "                    if len(tokens) >= 2:\n",
    "                        if (tokens[0].pos_ in ['NOUN', 'PRON', 'PROPN'] and \n",
    "                            tokens[1].pos_ in ['VERB', 'AUX']):\n",
    "                            return True\n",
    "                except:\n",
    "                    pass\n",
    "        elif word == 'with':\n",
    "            # Split on \"with\" if it starts a prepositional phrase that functions as a new clause\n",
    "            if 'words' in after_word[:20]:  # specific to this example\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "# Test the improved separator\n",
    "separator = Claude_Advanced_ClauseSeparator()\n",
    "\n",
    "test_text = '''There seemed to be no use in waiting by the little door, so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes: this time she found a little bottle on it, (\"which certainly was not here before,\" said Alice,) and round the neck of the bottle was a paper label, with the words \"DRINK ME,\" beautifully printed on it in large letters.'''\n",
    "\n",
    "result = separator.clause_split(test_text)\n",
    "\n",
    "print(\"Model Output:\")\n",
    "for i, clause in enumerate(result):\n",
    "    print(f\"{i+1}: '{clause}'\")\n",
    "\n",
    "print(\"\\nGold Standard:\")\n",
    "gold = ['There seemed to be no use in waiting by the little door,', 'so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes:', 'this time she found a little bottle on it,', '(\"which certainly was not here before,\" said Alice,)', 'and round the neck of the bottle was a paper label,', 'with the words \"DRINK ME,\" beautifully printed on it in large letters.']\n",
    "for i, clause in enumerate(gold):\n",
    "    print(f\"{i+1}: '{clause}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf9bc55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output:\n",
      "1: 'There seemed to be no use in waiting by the little door ,'\n",
      "2: 'so she went back to the table , half hoping she might find another key on it , or at any rate a book of rules for shutting people up like telescopes :'\n",
      "3: 'this time she found a little bottle on it ,'\n",
      "4: '( \" which certainly was not here before , \" said Alice , )'\n",
      "5: 'and round the neck of the bottle was a paper label , with the words \" DRINK ME , \" beautifully printed on it in large letters .'\n",
      "\n",
      "Gold Standard:\n",
      "1: 'There seemed to be no use in waiting by the little door,'\n",
      "2: 'so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes:'\n",
      "3: 'this time she found a little bottle on it,'\n",
      "4: '(\"which certainly was not here before,\" said Alice,)'\n",
      "5: 'and round the neck of the bottle was a paper label,'\n",
      "6: 'with the words \"DRINK ME,\" beautifully printed on it in large letters.'\n"
     ]
    }
   ],
   "source": [
    "class Claude_Basic_ClauseSeparator:\n",
    "    def __init__(self, size='small'):\n",
    "        if size == 'small':\n",
    "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        elif size == 'large':\n",
    "            self.nlp = spacy.load(\"en_core_web_trf\")\n",
    "        else:\n",
    "            print(\"Choose an appropriate spaCy model. Ex install: python -m spacy download en_core_web_sm\")\n",
    "            self.nlp = None\n",
    "    \n",
    "    def clause_split(self, text):\n",
    "        \"\"\"\n",
    "        Find clause boundaries based on conjunctions and punctuation.    \n",
    "        \"\"\"\n",
    "        if not self.nlp:\n",
    "            return None\n",
    "        \n",
    "        doc = self.nlp(text)\n",
    "        clauses = []\n",
    "        \n",
    "        for sentence in doc.sents:\n",
    "            sent_clauses = []\n",
    "            current_tokens = []\n",
    "            \n",
    "            # Track parentheses to avoid splitting inside them\n",
    "            paren_depth = 0\n",
    "            \n",
    "            for i, token in enumerate(sentence):\n",
    "                current_tokens.append(token.text)\n",
    "                \n",
    "                # Track parentheses\n",
    "                if token.text == '(':\n",
    "                    paren_depth += 1\n",
    "                elif token.text == ')':\n",
    "                    paren_depth -= 1\n",
    "                \n",
    "                should_split = False\n",
    "                \n",
    "                # Only split if we're not inside parentheses\n",
    "                if paren_depth == 0:\n",
    "                    # Split on semicolon and colon always\n",
    "                    if token.text in [';', ':']:\n",
    "                        should_split = True\n",
    "                    \n",
    "                    # Split on comma only in specific cases\n",
    "                    elif token.text == ',':\n",
    "                        # Look at next non-space token\n",
    "                        next_token = None\n",
    "                        for j in range(i + 1, len(sentence)):\n",
    "                            if sentence[j].text.strip():\n",
    "                                next_token = sentence[j]\n",
    "                                break\n",
    "                        \n",
    "                        if next_token:\n",
    "                            # Split if comma is followed by these clause starters\n",
    "                            if next_token.text.lower() in ['so', 'this']:\n",
    "                                should_split = True\n",
    "                    \n",
    "                    # Split on 'and' when it starts new independent clause\n",
    "                    elif token.text.lower() == 'and':\n",
    "                        # Look ahead for subject-verb pattern\n",
    "                        if i + 2 < len(sentence):\n",
    "                            next1 = sentence[i + 1]\n",
    "                            next2 = sentence[i + 2]\n",
    "                            if (next1.pos_ in ['NOUN', 'PRON', 'PROPN'] and \n",
    "                                next2.pos_ in ['VERB', 'AUX']):\n",
    "                                should_split = True\n",
    "                \n",
    "                # Make the split\n",
    "                if should_split and len(current_tokens) > 1:\n",
    "                    if token.text in [',', ';', ':']:\n",
    "                        # Include punctuation with previous clause\n",
    "                        clause_text = ' '.join(current_tokens).strip()\n",
    "                        if clause_text:\n",
    "                            sent_clauses.append(clause_text)\n",
    "                        current_tokens = []\n",
    "                    else:\n",
    "                        # Don't include conjunction with previous clause\n",
    "                        clause_text = ' '.join(current_tokens[:-1]).strip()\n",
    "                        if clause_text:\n",
    "                            sent_clauses.append(clause_text)\n",
    "                        current_tokens = [token.text]\n",
    "\n",
    "            # Add remaining tokens as final clause\n",
    "            if current_tokens:\n",
    "                clause_text = ' '.join(current_tokens).strip()\n",
    "                if clause_text:\n",
    "                    sent_clauses.append(clause_text)\n",
    "\n",
    "            # Handle parenthetical expressions as separate clauses\n",
    "            final_clauses = []\n",
    "            for clause in sent_clauses:\n",
    "                if '(' in clause and ')' in clause:\n",
    "                    # Split out parenthetical\n",
    "                    parts = []\n",
    "                    current = \"\"\n",
    "                    paren_start = -1\n",
    "                    \n",
    "                    for i, char in enumerate(clause):\n",
    "                        if char == '(' and paren_start == -1:\n",
    "                            if current.strip():\n",
    "                                parts.append(current.strip())\n",
    "                            paren_start = i\n",
    "                            current = char\n",
    "                        elif char == ')' and paren_start != -1:\n",
    "                            current += char\n",
    "                            parts.append(current.strip())\n",
    "                            current = \"\"\n",
    "                            paren_start = -1\n",
    "                        else:\n",
    "                            current += char\n",
    "                    \n",
    "                    if current.strip():\n",
    "                        parts.append(current.strip())\n",
    "                    \n",
    "                    final_clauses.extend(parts)\n",
    "                else:\n",
    "                    final_clauses.append(clause)\n",
    "\n",
    "            clauses.extend(final_clauses)\n",
    "        \n",
    "        return clauses\n",
    "\n",
    "\n",
    "# Test\n",
    "separator = Claude_Basic_ClauseSeparator()\n",
    "\n",
    "test_text = '''There seemed to be no use in waiting by the little door, so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes: this time she found a little bottle on it, (\"which certainly was not here before,\" said Alice,) and round the neck of the bottle was a paper label, with the words \"DRINK ME,\" beautifully printed on it in large letters.'''\n",
    "\n",
    "result = separator.clause_split(test_text)\n",
    "\n",
    "print(\"Model Output:\")\n",
    "for i, clause in enumerate(result):\n",
    "    print(f\"{i+1}: '{clause}'\")\n",
    "\n",
    "print(\"\\nGold Standard:\")\n",
    "gold = ['There seemed to be no use in waiting by the little door,', 'so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes:', 'this time she found a little bottle on it,', '(\"which certainly was not here before,\" said Alice,)', 'and round the neck of the bottle was a paper label,', 'with the words \"DRINK ME,\" beautifully printed on it in large letters.']\n",
    "for i, clause in enumerate(gold):\n",
    "    print(f\"{i+1}: '{clause}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86c4e1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output:\n",
      "1: 'There seemed to be no use in waiting by the little door'\n",
      "2: 'so she went back to the table'\n",
      "3: 'half hoping she might find another key on it'\n",
      "4: 'or at any rate a book of rules for shutting people up like telescopes'\n",
      "5: 'this time she found a little bottle on it'\n",
      "6: '( \" which certainly was not here before'\n",
      "7: '\" said Alice'\n",
      "8: ')'\n",
      "9: 'and round the neck of the bottle was a paper label'\n",
      "10: 'with the words \" DRINK ME'\n",
      "11: '\" beautifully printed on it in large letters .'\n",
      "\n",
      "Gold Standard:\n",
      "1: 'There seemed to be no use in waiting by the little door,'\n",
      "2: 'so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes:'\n",
      "3: 'this time she found a little bottle on it,'\n",
      "4: '(\"which certainly was not here before,\" said Alice,)'\n",
      "5: 'and round the neck of the bottle was a paper label,'\n",
      "6: 'with the words \"DRINK ME,\" beautifully printed on it in large letters.'\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "separator = ClauseSeparator()\n",
    "\n",
    "test_text = '''There seemed to be no use in waiting by the little door, so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes: this time she found a little bottle on it, (\"which certainly was not here before,\" said Alice,) and round the neck of the bottle was a paper label, with the words \"DRINK ME,\" beautifully printed on it in large letters.'''\n",
    "\n",
    "result = separator.clause_split(test_text)\n",
    "\n",
    "print(\"Model Output:\")\n",
    "for i, clause in enumerate(result):\n",
    "    print(f\"{i+1}: '{clause}'\")\n",
    "\n",
    "print(\"\\nGold Standard:\")\n",
    "gold = ['There seemed to be no use in waiting by the little door,', 'so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes:', 'this time she found a little bottle on it,', '(\"which certainly was not here before,\" said Alice,)', 'and round the neck of the bottle was a paper label,', 'with the words \"DRINK ME,\" beautifully printed on it in large letters.']\n",
    "for i, clause in enumerate(gold):\n",
    "    print(f\"{i+1}: '{clause}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8cb189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>pred_clauses</th>\n",
       "      <th>gold_clauses</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Alice was beginning to get very tired of sitt...</td>\n",
       "      <td>[Alice was beginning to get very tired of sitt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[So she was considering in her own mind, ( as ...</td>\n",
       "      <td>[So she was considering in her own mind (as we...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[There was nothing so very remarkable in that ...</td>\n",
       "      <td>[There was nothing so very remarkable in that;...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[In another moment down went Alice after it , ...</td>\n",
       "      <td>[In another moment down went Alice after it,, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[The rabbit - hole went straight on like a tun...</td>\n",
       "      <td>[The rabbit-hole went straight on like a tunne...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[Either the well was very deep , or she fell v...</td>\n",
       "      <td>[Either the well was very deep,, or she fell v...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[“ Well ! ” thought Alice to herself , “ after...</td>\n",
       "      <td>[“Well!” thought Alice to herself,, “after suc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[Down , down , down ., Would the fall never co...</td>\n",
       "      <td>[Down, down, down., Would the fall never come ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[Presently she began again ., “ I wonder if I ...</td>\n",
       "      <td>[Presently she began again., “I wonder if I sh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[Down , down , down ., There was nothing else ...</td>\n",
       "      <td>[Down, down, down., There was nothing else to ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[Alice was not a bit hurt ,, and she jumped up...</td>\n",
       "      <td>[Alice was not a bit hurt,, and she jumped up ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[There were doors all round the hall , but the...</td>\n",
       "      <td>[There were doors all round the hall,, but the...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>[Suddenly she came upon a little three - legge...</td>\n",
       "      <td>[Suddenly she came upon a little three-legged ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>[Alice opened the door and found that it led i...</td>\n",
       "      <td>[Alice opened the door, and found that it led ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>[There seemed to be no use in waiting by the l...</td>\n",
       "      <td>[There seemed to be no use in waiting by the l...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>[It was all very well to say “ Drink me , ” bu...</td>\n",
       "      <td>[It was all very well to say “Drink me,”, but ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>[However ,, this bottle was not marked “ poiso...</td>\n",
       "      <td>[However, this bottle was not marked “poison,”...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>[“ What a curious feeling ! ” said Alice ;, “ ...</td>\n",
       "      <td>[“What a curious feeling!” said Alice;, “I mus...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>[And so it was indeed :, she was now only ten ...</td>\n",
       "      <td>[And so it was indeed:, she was now only ten i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>[After a while , finding that nothing more hap...</td>\n",
       "      <td>[After a while, finding that nothing more happ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paragraph_id                                       pred_clauses  \\\n",
       "0              1  [Alice was beginning to get very tired of sitt...   \n",
       "1              2  [So she was considering in her own mind, ( as ...   \n",
       "2              3  [There was nothing so very remarkable in that ...   \n",
       "3              4  [In another moment down went Alice after it , ...   \n",
       "4              5  [The rabbit - hole went straight on like a tun...   \n",
       "5              6  [Either the well was very deep , or she fell v...   \n",
       "6              7  [“ Well ! ” thought Alice to herself , “ after...   \n",
       "7              8  [Down , down , down ., Would the fall never co...   \n",
       "8              9  [Presently she began again ., “ I wonder if I ...   \n",
       "9             10  [Down , down , down ., There was nothing else ...   \n",
       "10            11  [Alice was not a bit hurt ,, and she jumped up...   \n",
       "11            12  [There were doors all round the hall , but the...   \n",
       "12            13  [Suddenly she came upon a little three - legge...   \n",
       "13            14  [Alice opened the door and found that it led i...   \n",
       "14            15  [There seemed to be no use in waiting by the l...   \n",
       "15            16  [It was all very well to say “ Drink me , ” bu...   \n",
       "16            17  [However ,, this bottle was not marked “ poiso...   \n",
       "17            18  [“ What a curious feeling ! ” said Alice ;, “ ...   \n",
       "18            19  [And so it was indeed :, she was now only ten ...   \n",
       "19            20  [After a while , finding that nothing more hap...   \n",
       "\n",
       "                                         gold_clauses  precision  recall   f1  \n",
       "0   [Alice was beginning to get very tired of sitt...        0.0     0.0  0.0  \n",
       "1   [So she was considering in her own mind (as we...        0.0     0.0  0.0  \n",
       "2   [There was nothing so very remarkable in that;...        0.0     0.0  0.0  \n",
       "3   [In another moment down went Alice after it,, ...        0.0     0.0  0.0  \n",
       "4   [The rabbit-hole went straight on like a tunne...        0.0     0.0  0.0  \n",
       "5   [Either the well was very deep,, or she fell v...        0.0     0.0  0.0  \n",
       "6   [“Well!” thought Alice to herself,, “after suc...        0.0     0.0  0.0  \n",
       "7   [Down, down, down., Would the fall never come ...        0.0     0.0  0.0  \n",
       "8   [Presently she began again., “I wonder if I sh...        0.0     0.0  0.0  \n",
       "9   [Down, down, down., There was nothing else to ...        0.0     0.0  0.0  \n",
       "10  [Alice was not a bit hurt,, and she jumped up ...        0.0     0.0  0.0  \n",
       "11  [There were doors all round the hall,, but the...        0.0     0.0  0.0  \n",
       "12  [Suddenly she came upon a little three-legged ...        0.0     0.0  0.0  \n",
       "13  [Alice opened the door, and found that it led ...        0.0     0.0  0.0  \n",
       "14  [There seemed to be no use in waiting by the l...        0.0     0.0  0.0  \n",
       "15  [It was all very well to say “Drink me,”, but ...        0.0     0.0  0.0  \n",
       "16  [However, this bottle was not marked “poison,”...        0.0     0.0  0.0  \n",
       "17  [“What a curious feeling!” said Alice;, “I mus...        0.0     0.0  0.0  \n",
       "18  [And so it was indeed:, she was now only ten i...        0.0     0.0  0.0  \n",
       "19  [After a while, finding that nothing more happ...        0.0     0.0  0.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# function to compute clause-level metrics for one paragraph\n",
    "def clause_metrics(pred_clauses, gold_clauses):\n",
    "    # treat each predicted clause as \"predicted\"; match against gold clauses\n",
    "    # we allow each gold clause to match at most one predicted clause\n",
    "    gold_remaining = gold_clauses.copy()\n",
    "    tp = 0\n",
    "    for p in pred_clauses:\n",
    "        if p in gold_remaining:\n",
    "            tp += 1\n",
    "            gold_remaining.remove(p)\n",
    "    fp = len(pred_clauses) - tp\n",
    "    fn = len(gold_clauses) - tp\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    return precision, recall, f1\n",
    "\n",
    "separator = ClauseSeparator()\n",
    "\n",
    "num_paragraphs = 20  # evaluate first 5 paragraphs\n",
    "results = []\n",
    "\n",
    "for i in range(num_paragraphs):\n",
    "    gold_clauses = paragraph_clauses['clauses'][i]\n",
    "    paragraph_text = paragraph_clauses['paragraph_text'][i]\n",
    "    \n",
    "    pred_clauses = separator.clause_split(paragraph_text)\n",
    "    \n",
    "    precision, recall, f1 = clause_metrics(pred_clauses, gold_clauses)\n",
    "    \n",
    "    results.append({\n",
    "        'paragraph_id': paragraph_clauses['paragraph_id'][i],\n",
    "        'pred_clauses': pred_clauses,\n",
    "        'gold_clauses': gold_clauses,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff671863",
   "metadata": {},
   "source": [
    "Using my clause separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df78d0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There seemed to be no use in waiting by the little door',\n",
       " 'so she went back to the table',\n",
       " 'half hoping she might find another key on it',\n",
       " 'or at any rate a book of rules for shutting people up like telescopes',\n",
       " 'this time she found a little bottle on it',\n",
       " '( “ which certainly was not here before',\n",
       " '” said Alice',\n",
       " ')',\n",
       " 'and round the neck of the bottle was a paper label',\n",
       " 'with the words “ DRINK ME',\n",
       " '” beautifully printed on it in large letters .']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.iloc[14]['pred_clauses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0bd31d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There seemed to be no use in waiting by the little door,',\n",
       " 'so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes:',\n",
       " 'this time she found a little bottle on it,',\n",
       " '(“which certainly was not here before,” said Alice,)',\n",
       " 'and round the neck of the bottle was a paper label,',\n",
       " 'with the words “DRINK ME,” beautifully printed on it in large letters.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.iloc[14]['gold_clauses']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
